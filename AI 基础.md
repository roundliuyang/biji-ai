# AI 基础



## 参数量

 **模型参数量（AI 领域）**

- 定义：指机器学习模型中可调整的权重（数值），用于存储从训练数据中学到的知识。
  - 例如：我的 1750 亿参数 是神经网络中神经元之间的连接权重。
- 作用：参数越多，模型通常能处理更复杂的任务（但需要更多计算资源）。
- 存储形式：通常是浮点数矩阵（如 `FP16` 或 `BF16` 格式）。

模型参数量 ：是指机器学习（尤其是深度学习）模型中所有可调整的权重（Weight）和偏置（Bias）的总数。这些参数是模型通过训练数据自动学习得到的，决定了模型如何对输入数据进行计算和预测。下面从多个角度详细解释：

------

### 1. 参数的本质

- 权重（Weights）：神经元之间的连接强度（例如矩阵中的浮点数）。
- 偏置（Biases）：神经元的激活阈值（偏移量）。
- 举例：
  一个简单的线性层 `y = Wx + b` 中，`W` 是权重矩阵，`b` 是偏置向量，它们的元素都是模型的参数。

------

### 2. 参数的作用

- 存储知识：参数编码了模型从训练数据中学到的规律（如语言规则、图像特征等）。
- 影响输出：输入数据经过层层参数计算后，最终生成预测结果（如文本生成、分类概率）。

------

### 3. 参数量与模型规模

- 小模型：参数量在百万（M）级（例如手机端模型）。
- 大模型（LLM）：参数量在千亿（B）到万亿（T）级（如GPT-3的175B）。
- 我的参数量：1750亿（175B），属于大语言模型。

------

### 4. 如何计算参数量？

以神经网络为例：

- 全连接层：输入维度 `m`，输出维度 `n` → 参数量 = `m×n + n`（权重+偏置）。
- Transformer模型：参数量主要来自：
  - 注意力层的 `Q/K/V` 矩阵
  - 前馈网络（FFN）的权重
  - 词嵌入（Embedding）矩阵
- 公式：总参数量 = 各层参数量之和。

------

### 5. 参数量 vs. 性能

- 更多参数：通常能提升模型能力（如理解复杂上下文），但需要更多计算资源。
- 过大的参数量：可能导致过拟合或训练困难，需结合数据量和架构设计平衡。





## 资料

【北京大学】DeepSeek原理与落地应用+ +1 人工智能概念辨析

